#!/usr/bin/env python3
"""
amzn.toãƒªãƒ³ã‚¯ã‹ã‚‰ASINã‚’æŠ½å‡ºã—ã€sampleData.jsã‚’æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    uv run python scripts/extractAsin.py
"""

import re
import urllib.request
from pathlib import Path
import time


def extract_asin_from_url(url: str) -> str | None:
    """Amazonã®URLã‹ã‚‰ASINã‚’æŠ½å‡ºã™ã‚‹"""
    # /dp/{ASIN} ã¾ãŸã¯ /gp/product/{ASIN} ãƒ‘ã‚¿ãƒ¼ãƒ³
    patterns = [
        r"/dp/([A-Z0-9]{10})",
        r"/gp/product/([A-Z0-9]{10})",
        r"/product/([A-Z0-9]{10})",
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None


def resolve_short_url(short_url: str) -> str | None:
    """amzn.toã®çŸ­ç¸®URLã‚’å±•é–‹ã—ã¦ASINã‚’å–å¾—ã™ã‚‹"""
    if not short_url or not short_url.startswith("https://amzn.to/"):
        return None

    try:
        # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’è¿½ã£ã¦final URLã‚’å–å¾—
        req = urllib.request.Request(short_url)
        req.add_header("User-Agent", "Mozilla/5.0")
        with urllib.request.urlopen(req, timeout=10) as response:
            html_content = response.read().decode('utf-8', errors='ignore')
            
            # HTMLã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºï¼ˆdata-old-hireså±æ€§ã‹ã‚‰ï¼‰
            # ãƒ‘ã‚¿ãƒ¼ãƒ³: "https://m.media-amazon.com/images/I/{IMAGE_ID}._SL1500_.jpg"
            image_patterns = [
                r'data-old-hires["\']:\s*["\']https://m\.media-amazon\.com/images/I/([A-Z0-9]+)\.',
                r'"hiRes":\s*"https://m\.media-amazon\.com/images/I/([A-Z0-9]+)\.',
                r'"large":\s*"https://m\.media-amazon\.com/images/I/([A-Z0-9]+)\.',
            ]
            
            for pattern in image_patterns:
                match = re.search(pattern, html_content)
                if match:
                    image_id = match.group(1)
                    print(f"  ğŸ–¼ï¸  ç”»åƒID: {image_id}")
                    return image_id
            
            # ç”»åƒIDãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€URLã‹ã‚‰ASINã‚’æŠ½å‡º
            final_url = response.url
            asin = extract_asin_from_url(final_url)
            if asin:
                print(f"  ğŸ“¦ å•†å“ASIN: {asin} (ç”»åƒIDãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ä»£ç”¨)")
            return asin
            
    except Exception as e:
        print(f"  ã‚¨ãƒ©ãƒ¼: {short_url} - {e}")
        return None


def update_sample_data(file_path: Path) -> int:
    """sampleData.jsãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¦ASINã‚’è¿½åŠ ã™ã‚‹"""
    content = file_path.read_text(encoding="utf-8")
    
    # amzn.toãƒªãƒ³ã‚¯ã‚’æŒã¤æ›¸ç±ã‚’æ¤œç´¢
    amazon_pattern = r'amazon:\s*"(https://amzn\.to/[^"]+)"'
    matches = list(re.finditer(amazon_pattern, content))
    
    print(f"ğŸ“š {len(matches)} ä»¶ã®Amazonãƒªãƒ³ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸ\n")
    
    # ASINã‚’åé›†
    asin_map = {}  # amazon_url -> asin
    for i, match in enumerate(matches):
        amazon_url = match.group(1)
        print(f"[{i + 1}/{len(matches)}] {amazon_url}")
        
        asin = resolve_short_url(amazon_url)
        if asin:
            asin_map[amazon_url] = asin
            print(f"  âœ… ASIN: {asin}")
        else:
            print(f"  âš ï¸  ASINæŠ½å‡ºå¤±æ•—")
        
        time.sleep(0.3)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
    
    if not asin_map:
        print("\næ›´æ–°å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return 0
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ï¼šyearè¡Œã®å¾Œã«asinã‚’æŒ¿å…¥
    updated_content = content
    added_count = 0
    
    for amazon_url, asin in asin_map.items():
        # amazon URLã®ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹
        amazon_pos = updated_content.find(f'amazon: "{amazon_url}"')
        if amazon_pos == -1:
            continue
        
        # ã“ã®æ›¸ç±ã‚¨ãƒ³ãƒˆãƒªã®é–‹å§‹ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹
        before_amazon = updated_content[:amazon_pos]
        
        # ã‚¨ãƒ³ãƒˆãƒªå†…ã«ã™ã§ã«asinãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        # æœ€ã‚‚è¿‘ã„ "year:" ã‚’è¦‹ã¤ã‘ã‚‹
        year_pos = before_amazon.rfind("year:")
        if year_pos == -1:
            continue
        
        section = updated_content[year_pos:amazon_pos]
        if "asin:" in section:
            print(f"  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢ã«asinå­˜åœ¨ï¼‰: {amazon_url}")
            continue
        
        # yearè¡Œã®çµ‚ã‚ã‚Šï¼ˆæ”¹è¡Œï¼‰ã‚’è¦‹ã¤ã‘ã¦ã€ãã®å¾Œã«asinã‚’æŒ¿å…¥
        year_line_end = updated_content.find("\n", year_pos)
        if year_line_end == -1:
            continue
        
        # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’å–å¾—ï¼ˆyearè¡Œã®ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
        line_start = updated_content.rfind("\n", 0, year_pos) + 1
        indent_match = re.match(r"(\s*)", updated_content[line_start:])
        indent = indent_match.group(1) if indent_match else "    "
        
        # asinè¡Œã‚’æŒ¿å…¥
        insert_pos = year_line_end + 1
        asin_line = f'{indent}asin: "{asin}",\n'
        
        updated_content = (
            updated_content[:insert_pos] + asin_line + updated_content[insert_pos:]
        )
        added_count += 1
        print(f"  â• asinè¿½åŠ : {asin}")
    
    if added_count > 0:
        file_path.write_text(updated_content, encoding="utf-8")
        print(f"\nâœ¨ {added_count} ä»¶ã®ASINã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    else:
        print("\næ›´æ–°ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return added_count


def main():
    print("ğŸ” Amazon ASINã‚’æŠ½å‡ºã—ã¾ã™...\n")
    
    script_dir = Path(__file__).parent
    sample_data_path = script_dir.parent / "src" / "data" / "sampleData.js"
    
    if not sample_data_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sample_data_path}")
        return
    
    update_sample_data(sample_data_path)


if __name__ == "__main__":
    main()
